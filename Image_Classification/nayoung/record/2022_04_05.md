# EfficientDet

```
conda create -n effdet --clone detection
conda activate effdet

git clone https://github.com/rwightman/efficientdet-pytorch.git  
cd efficientdet-pytorch  
pip install -r requirements.txt
pip install -v -e .
```

```
# effdet/data/dataset_config.py 파일 수정

class Coco2017Cfg(CocoCfg):
    variant: str = '2017'
    splits: Dict[str, dict] = field(default_factory=lambda: dict(
        train=dict(ann_filename=[train파일], img_dir='', has_labels=True),
        val=dict(ann_filename=[val파일], img_dir='', has_labels=True),
        test=dict(ann_filename=[test파일], img_dir='', has_labels=False)
    ))
```

### train

```
python train.py [dataset 경로] --model tf_efficientdet_d4_ap -b 4 
--amp --lr .008 --model-ema --model-ema-decay 0.9966 --epochs 70 
--num-classes 10 --tta 1 --pretrained
```

```
python train.py /opt/ml/detection/dataset --model tf_efficientdet_d7 -b 8 \
--amp --lr .008 --model-ema --model-ema-decay 0.9966 --epochs 70 --num-classes 10 \ 
--tta 1 --pretrained --color-jitter 0.5
```

### inference

```
python validate.py [dataset 경로] --model tf_efficientdet_d4_ap --dataset coco \
--split test --num-gpu 1 -b 1 --checkpoint [checkpoint 경로] --num-classes 10 \
--results [결과 생성할 경로]
```

### submit.py

```dart
import json
import pandas as pd

def main():
    id=-1
    Prediction_strings=[]
    file_names=[]

    json_root='/opt/ml/detection/baseline/efficientdet-pytorch/result.json'
    
    with open(json_root,'r') as f:
        results=json.load(f)
    
    Prediction_string = ''
    for i, result in enumerate(results): 
        xmin=str(result['bbox'][0])
        ymin=str(result['bbox'][1])
        xmax=str(result['bbox'][0]+result['bbox'][2])
        ymax=str(result['bbox'][1]+result['bbox'][3])

        if id < result['image_id']: # 같은 id의 첫번째 값 
            # image id 작성 및 추가  
            file_name = 'test/' + str(result['image_id']).zfill(4) + '.jpg'
            file_names.append(file_name)
            id = result['image_id']
             
            # Prediction_string 작성  
            Prediction_string = ''
            Prediction_string += str(result['category_id']-1) + ' ' + str(result['score']) + ' ' + xmin + ' ' + ymin + ' ' + xmax + ' ' + ymax + ' ' 

        elif result['image_id']!= 4870 : # 같은 id의 중간값 들 
            if result['image_id'] < results[i+1]['image_id']: # 같은 id의 마지막번째 값 
                Prediction_string += str(result['category_id']-1) + ' ' + str(result['score']) + ' ' + xmin + ' ' + ymin + ' ' + xmax + ' ' + ymax + ' ' 
                Prediction_strings.append(Prediction_string)
            else:
                Prediction_string += str(result['category_id']-1) + ' ' + str(result['score']) + ' ' + xmin + ' ' + ymin + ' ' + xmax + ' ' + ymax + ' ' 
        elif i==(len(results)-1): # 전체 id 중 맨 마지막 
            Prediction_string += str(result['category_id']-1) + ' ' + str(result['score']) + ' ' + xmin + ' ' + ymin + ' ' + xmax + ' ' + ymax + ' ' 
            Prediction_strings.append(Prediction_string)

    submission = pd.DataFrame()
    submission['PredictionString'] = Prediction_strings
    submission['image_id'] = file_names
    submission.to_csv('/opt/ml/detection/baseline/efficientdet-pytorch/submission.csv', index=None)

if __name__ == "__main__":
    main()
```

### 실행

```dart
python submit.py
```

### models

- 참고 : [efficientdet-pytorch/model_config.py at master · rwightman/efficientdet-pytorch (github.com)](https://github.com/rwightman/efficientdet-pytorch/blob/master/effdet/config/model_config.py)

# TypeError: create_loader() got an unexpected keyword argument 'color_jitter’

- create_loader에 color_jitter 항목 추가

# wandb error

```dart
Traceback (most recent call last):
  File "train.py", line 682, in <module>
    main()
  File "train.py", line 306, in main
    wandb.watch(args.model, log_freq=100)
  File "/opt/conda/envs/effdet/lib/python3.7/site-packages/wandb/sdk/wandb_watch.py", line 76, in watch
    + str(type(model))
ValueError: Expected a pytorch model (torch.nn.Module). Received <class 'str'>
```

- model 이름만 저장하는 것이 아니라, model.cuda()처럼 실제 모델을 wandb 인자로 넘겨야

# colorjitter

```dart
# import albumentations as A
from typing import Any, BinaryIO, List, Optional, Tuple, Union
import numbers

def _log_api_usage_once(obj: Any) -> None:

    """
    Logs API usage(module and name) within an organization.
    In a large ecosystem, it's often useful to track the PyTorch and
    TorchVision APIs usage. This API provides the similar functionality to the
    logging module in the Python stdlib. It can be used for debugging purpose
    to log which methods are used and by default it is inactive, unless the user
    manually subscribes a logger via the `SetAPIUsageLogger method <https://github.com/pytorch/pytorch/blob/eb3b9fe719b21fae13c7a7cf3253f970290a573e/c10/util/Logging.cpp#L114>`_.
    Please note it is triggered only once for the same API call within a process.
    It does not collect any data from open-source users since it is no-op by default.
    For more information, please refer to
    * PyTorch note: https://pytorch.org/docs/stable/notes/large_scale_deployments.html#api-usage-logging;
    * Logging policy: https://github.com/pytorch/vision/issues/5052;
    Args:
        obj (class instance or method): an object to extract info from.
    """
    if not obj.__module__.startswith("torchvision"):
        return
    name = obj.__class__.__name__
    if isinstance(obj, FunctionType):
        name = obj.__name__
    torch._C._log_api_usage_once(f"{obj.__module__}.{name}")

####

# ColorJitter
class ColorJitter(torch.nn.Module):
    """Randomly change the brightness, contrast, saturation and hue of an image.
    If the image is torch Tensor, it is expected
    to have [..., 1 or 3, H, W] shape, where ... means an arbitrary number of leading dimensions.
    If img is PIL Image, mode "1", "I", "F" and modes with transparency (alpha channel) are not supported.

    Args:
        brightness (float or tuple of float (min, max)): How much to jitter brightness.
            brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]
            or the given [min, max]. Should be non negative numbers.
        contrast (float or tuple of float (min, max)): How much to jitter contrast.
            contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]
            or the given [min, max]. Should be non negative numbers.
        saturation (float or tuple of float (min, max)): How much to jitter saturation.
            saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]
            or the given [min, max]. Should be non negative numbers.
        hue (float or tuple of float (min, max)): How much to jitter hue.
            hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].
            Should have 0<= hue <= 0.5 or -0.5 <= min <= max <= 0.5.
            To jitter hue, the pixel values of the input image has to be non-negative for conversion to HSV space;
            thus it does not work if you normalize your image to an interval with negative values,
            or use an interpolation that generates negative values before using this function.
    """

    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):
        super().__init__()
        _log_api_usage_once(self)
        self.brightness = self._check_input(brightness, "brightness")
        self.contrast = self._check_input(contrast, "contrast")
        self.saturation = self._check_input(saturation, "saturation")
        self.hue = self._check_input(hue, "hue", center=0, bound=(-0.5, 0.5), clip_first_on_zero=False)

    @torch.jit.unused
    def _check_input(self, value, name, center=1, bound=(0, float("inf")), clip_first_on_zero=True):
        if isinstance(value, numbers.Number):
            if value < 0:
                raise ValueError(f"If {name} is a single number, it must be non negative.")
            value = [center - float(value), center + float(value)]
            if clip_first_on_zero:
                value[0] = max(value[0], 0.0)
        elif isinstance(value, (tuple, list)) and len(value) == 2:
            if not bound[0] <= value[0] <= value[1] <= bound[1]:
                raise ValueError(f"{name} values should be between {bound}")
        else:
            raise TypeError(f"{name} should be a single number or a list/tuple with length 2.")

        # if value is 0 or (1., 1.) for brightness/contrast/saturation
        # or (0., 0.) for hue, do nothing
        if value[0] == value[1] == center:
            value = None
        return value

    @staticmethod
    def get_params(
        brightness: Optional[List[float]],
        contrast: Optional[List[float]],
        saturation: Optional[List[float]],
        hue: Optional[List[float]],
    ) -> Tuple[torch.Tensor, Optional[float], Optional[float], Optional[float], Optional[float]]:
        """Get the parameters for the randomized transform to be applied on image.

        Args:
            brightness (tuple of float (min, max), optional): The range from which the brightness_factor is chosen
                uniformly. Pass None to turn off the transformation.
            contrast (tuple of float (min, max), optional): The range from which the contrast_factor is chosen
                uniformly. Pass None to turn off the transformation.
            saturation (tuple of float (min, max), optional): The range from which the saturation_factor is chosen
                uniformly. Pass None to turn off the transformation.
            hue (tuple of float (min, max), optional): The range from which the hue_factor is chosen uniformly.
                Pass None to turn off the transformation.

        Returns:
            tuple: The parameters used to apply the randomized transform
            along with their random order.
        """
        fn_idx = torch.randperm(4)

        b = None if brightness is None else float(torch.empty(1).uniform_(brightness[0], brightness[1]))
        c = None if contrast is None else float(torch.empty(1).uniform_(contrast[0], contrast[1]))
        s = None if saturation is None else float(torch.empty(1).uniform_(saturation[0], saturation[1]))
        h = None if hue is None else float(torch.empty(1).uniform_(hue[0], hue[1]))

        return fn_idx, b, c, s, h

    def forward(self, img):
        """
        Args:
            img (PIL Image or Tensor): Input image.

        Returns:
            PIL Image or Tensor: Color jittered image.
        """
        fn_idx, brightness_factor, contrast_factor, saturation_factor, hue_factor = self.get_params(
            self.brightness, self.contrast, self.saturation, self.hue
        )

        for fn_id in fn_idx:
            if fn_id == 0 and brightness_factor is not None:
                img = F.adjust_brightness(img, brightness_factor)
            elif fn_id == 1 and contrast_factor is not None:
                img = F.adjust_contrast(img, contrast_factor)
            elif fn_id == 2 and saturation_factor is not None:
                img = F.adjust_saturation(img, saturation_factor)
            elif fn_id == 3 and hue_factor is not None:
                img = F.adjust_hue(img, hue_factor)

        return img

    def __repr__(self) -> str:
        s = (
            f"{self.__class__.__name__}("
            f"brightness={self.brightness}"
            f", contrast={self.contrast}"
            f", saturation={self.saturation}"
            f", hue={self.hue})"
        )
        return s
```

- color jitter를 적용하려고 시도했으나, 에러 발생

### 해결

```
class Transform:
    def __call__(self, pil_img, annotations: dict):
        np_img = np.array(pil_img, dtype=np.uint8)
        np_img = np.transpose(np_img, (1, 2, 0))
        
        transform = albumentations.Compose([
            albumentations.augmentations.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5,p=1.0)
        ])
        
        new_img = transform(image=np_img)['image']

        new_img = np.transpose(new_img, (2, 0, 1))
        return new_img, annotations
```

- augmentation 결과로 image, annotation이 모두 리턴되어야 하는데, Compose에 transforms.ColorJitter()만 적용할 경우, 다른 augmentation과 함께 사용할 수 없음 ⇒ ColorJitter 클래스를 따로 만들어서 Compose에 넣기

# 에러
## ‘dict’ object has no attribute ‘shape’
```
transformed = transform(image=image) (X)
transformed = transform(image=image)['image'] (O)
```
- 참고 : https://forum.edgeimpulse.com/t/dict-object-has-no-attribute-shape/2132/4
